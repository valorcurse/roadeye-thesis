% #####################################################################################################################################################################################
\hoofdstuk{Requirements}
% #####################################################################################################################################################################################

Even though a general goal and vision are important for guiding which direction the application goes towards, they must be broken down into smaller, more concrete and measurable objectives. These are called requirements and are used to determine the project’s progress and whether it was completed successfully or not. The following requirements were deduced from the project’s problem and objective:

\begin{enumerate}
    \item{\textbf{The application must be able to locate the license plate within an image.} \\
        One of the most important functionalities of the application, without this requirement most of the following requirements can not be accomplished. Must find a plate within an image where a plate is present and ignore everything else if no license plate is present.        
    }

    \item{\textbf{The application must be able to recognise the text displayed on the license plate.} \\
        The other requirement which ties the whole application together. Once the plate has been located, the text contained in the plate must be parsed so the application possesses information to work further. 
    }

    \item{\textbf{The application must be able to retrieve a list of license plates from a designated website.} \\
         For the application to be able to provide useful information about a certain vehicle, it must have information about stole vehicles to match the recognise plate text against. Therefore it must be able to retrieve that information from the place where it is available, in the case a website.
    }

    \item{\textbf{The application must be able to match the recognised text in the license plate to the retrieved list.} \\
        The application must be able to match the retrieved information of stolen vehicles with the recognised text.
    }

    \item{\textbf{The application must be to notify a central application whenever a match has been made.} \\
        When there's a match between the parsed information and the information retrieved from the website, the application must be able to send a notification about this information to a central application.
    }

    \item{\textbf{The application must be not save any information/images longer than necessary.} \\
        As to minimise the chance any privacy law will be broken, the application will not save any form of data which might be used to identify someone. The reason for this is explained in a later chapter.
    }

\end{enumerate}

% #####################################################################################################################################################################################
\hoofdstuk {Methodology}
% #####################################################################################################################################################################################

Before starting the development, the methods must be found which will be used to find viable ways of solving the problems presented by the requirements and how to implement them once the correct solutions have been found. For this reason some time was first spent searching for possible research and development methods. In the end the following choices were made.

\paragraaf{Research method}

The method applied for researching the problems of this project and its possible solutions is called \emph{literature review}. This method consists of researching what has already been published, which might be in the form of scientific or engineering papers, journals, thesis, etc., by accredited scientists, scholars or engineers concerning this assignment's topics. 
This method is used for searching for potential algorithms which can be used to solve the problems created by the requirements. Once a group of the most suitable algorithms has been found, the best one must be chosen and the reasoning for this choice must be explained. When the choice has been made, the algorithm is then implemented using the chosen development method.

This method was chosen because computer vision is a rather complex field of study and to be able to understand and apply it correctly, learning about the past work of like-minded researchers is a must. This project's research was done by searching for available papers on the internet. Starting with very general terms related to the topic of license plate location, the research became more and more refined by searching for papers and terms referred on each related document found. This way a large quantity of topics were researched which might have been valuable for the project. Eventually suitable algorithms were found when researching using this method.

\paragraaf{Development method}

After searching for and finding which development methods are used for developing software within the company, which are the waterfall method and the Scrum method, some time was spent researching which method was the most appropriate for this project. The waterfall method consists of a sequential design process of multiple phases. The flow of this method is illustrated in Figure \ref{fig:waterfall-method}. When using this method, the whole design process must be done during their own phases and cannot be interchanged. This presented a problem because of the lack of knowledge on the computer vision subject and on the development of Android applications, which made it difficult to foresee what kind difficulties might arise during the development. Because of this reason, this method was deemed too inflexible for this project.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{plaatjes/waterfall-method}
    \caption{The waterfall method.}
    \label{fig:waterfall-method}
\end{figure}%

The other method used within the company was Scrum, which is illustrated in Figure \ref{fig:scrum-method}. It works by dividing a project into smaller windows, called sprints, in which a feature is developed. At the end of each cycle its result is reviewed together with the customer to determine if the project is going in the desired direction. This method differs from the waterfall method because it focuses more on feedback than on previous planning. Using this method it's possible to tackle problems which were not possible to solve in a planned and predictive way. Such a method conforms better to the necessities of being able to revise the design and implementation of the project due to, for example, the lack of knowledge previously mentioned. But Scrum is intended to be used when developing software with a group. There is even a role within the group that is purely intended to make sure the rest of the group can do their work without any interruption, called the Scrum Master. Because this project was developed by one person, a similar development method had to be found which had all the benefits of Scrum but made solo development possible.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{plaatjes/scrum-method}
    \caption{The Scrum method.}
    \label{fig:scrum-method}
\end{figure}%


That method turned out to be the \emph{Iterative Application Development} (IAD) method. This development method works by dividing the project into smaller `sub-projects', called \emph{cycles}, and incrementing them to past cycles, which will ultimately lead to a complete system. Each cycle consists of three phases, which can be repeated multiple times if necessary, called \emph{iterations}. These iterations are: \emph{definition}, \emph{development} and \emph{deployment}.

During the definition phase the goals, limitations and conditions for the current cycle are examined and described. If a previous cycle has been completed, it will be evaluated during this phase. This phase is intended for thinking towards the completion of the project and to achieve a more clear picture of the system as a whole.
After defining the objective for the new cycle, the software will be developed. After finishing, the software is then integrated with the software developed in the previous cycles and becomes therefore part of the general project. This method of software development brings multiple benefits: The complexity of the project is decreased by breaking down the problem into smaller chunks, which allows for faster and more concrete results and makes it therefore easier to get better feedback or to solve critical bottlenecks by being able to discuss them at the end of each cycle. The project development also becomes more flexible by having the possibility to review the requirements and strategies every cycle. Each cycle lasts 2 weeks and at the end of each cycle the evaluation of the past cycle and the objective for the coming cycle will be discussed with the organisation's mentor.

Using this method it's possible to make up for the lack of knowledge on the by doing the research and implementation incrementally and dealing with problems whenever they arise instead of trying to predict beforehand what could go wrong during the development.

% #####################################################################################################################################################################################
\hoofdstuk{Algorithms}
% #####################################################################################################################################################################################

After reasoning about what kind of main algorithms and researching which software could be used to develop the application, the problem was then broken down into two different categories: localising the plate within an image, because it is a broad problem which can be solved in a different number of ways, and parsing the text within the plate, which is a more specific problem and there are available libraries which can be promptly used to solve this problem. After this realisation and researching the possibilities, the following choices were made:

\paragraaf{Plate localization}

When searching for possible algorithms which make it possible to find license plates in an image, two main types came forth from the research: feature detection and edge detection. 

The feature detection algorithms work by finding so called \emph{features} in a image, which are used to recognise the first image within a second one. These features are segments of an image which must be uncommon, as to reduce the possibility of retrieving a false positive when applying the algorithm, and also consist of something which can be objectively described to a computer. Because of these requirements, the features extracted from images are usually corners since corners usually only match themselves when compared to other segments in an image. This opposed to flat surfaces or lines, which may appear multiple times in multiple places in the same image. Because this algorithm focuses on detecting the uniqueness of an image and using those attributes to detect themselves in different images, it is difficult to use feature detection for the recognition of license plates for the reason that every license plate contains unique text. The considerable collection of diverse shapes that exist in the Latin alphabet create false positives which are often detected in random and incorrect locations. One possible approach to use this algorithm would be by creating a feature database of every possible alphanumeric character and then finding the highest concentration of text as a possible location. 

The other possible algorithm is mostly based on edge detection. This kind of algorithm works by applying an edge detection filter to a grey scale version of the image where the car is present. This creates a binary image where the edges of every shape present in the image are displayed. Because of the nature of one of the characteristics common to every license plate, which is the presence of text, an area with a high density of edges is created. Although license plates are not the only objects which might have such a property, e.g. a fence, it is the most common one which might be encountered while driving. By applying this filter to find horizontal edges it is possible to find the vertical location of the plate and then vice-versa to find the horizontal location and by extension the plate itself. Due to little information on the performance of the feature detection algorithm and a healthy amount of information regarding this one, this algorithm was chosen.

This algorithm was implemented using Open Computer Vision (OpenCV) library which is a library that contains optimized state-of-the-art computer vision algorithms. This library is maintained by Intel, a company known for its mathematical knowledge, is completely free, as in beer and as in freedom, and has an Android version. Because of these reasons and prior experience working with this library, OpenCV was chosen. Although the application was implemented using this library, this thesis explains the algorithms usage in a general, OpenCV-agnostic way as to be easier to understand the algorithms without the need for the library.


\paragraaf{Text recognition}

Text recognition is a specific problem which will only vary slightly from project to project, which usually means it has to be trained to recognise a different font or the text to be recognised has a special orientation, e.g. vertical or diagonal. There are libraries which have this specific functionality along with enough customisability to adjust the library to the specific needs of a project. There is for this reason no need to create an own text recognition algorithm.
From the available options in OCR technology, the Tesseract Optical Character Recognition (OCR) was chosen because it is maintained by Google, a company known for its OCR technology, because it is one of the most accurate free OCR libraries available, and because it also has an Android version. It was chosen because no there are no other free library available which can deliver the same type of results. The implementation of the text recognition is Tesseract specific because, as opposed to the plate localisation algorithm, it uses a very specific software package instead of a collection of algorithms.



% #####################################################################################################################################################################################
\hoofdstuk{Design}
% #####################################################################################################################################################################################

Before the application can be built, some sort of blueprint must be created where the functionality, the flow, and a variety of other specifications are incorporated and described. This is called the design of the application and it outlines what each component does, how they are interconnected, and the reasoning behind each choice.

\paragraaf{Privacy}

Privacy has always been an hot topic within the computer science circle of professions with computers becoming faster each year and all sort of algorithms being created which have the potential to invade the privacy of thousands if not millions of people. As of the writing of this thesis, a chain of events have gotten this kind of controversy to a new all-time high. 
To prevent that this application will ever create any privacy concerns, some research was done on the Dutch privacy law of personal information as of 2014. According to this law, it is only possible to transgress if, while collecting license plate information, the following three requirements are met. The information must be:

\begin{enumerate}
    \item{\textbf{personal information} \\
        The information gathered must qualify as personal information. This means the information must directly link to a certain person, e.g. phone number, address or name but also pictures of people's faces. The only instance which has access to the personal information linked to a license plate is the \textit{Rijksdienst voor het Wegverkeer}, which is a government instance, and therefore the only instance which would have to comply to the privacy law. It is possible to access that information through their services, but you need the information's owner's permission and have to pay a fee, which means accidental transgression of the law impossible is.
    }

    \item{\textbf{processed} \\
        Processing information is a very broad concept, which can be anything from using the information for a website or just matching it against a database.
    }

    \item{\textbf{saved in a file} \\
        This can be a simple spreadsheet or a full-fledged database.
    }
\end{enumerate}

This application will only meet the second point, which means it will not violate the Dutch privacy law. To add some additional certainty, the application will only save the license plate information for as long as necessary, will not save any pictures taken after they have been processed and the user will not have direct access to that information.

\paragraaf{Application}
The top-level flow of the system consists of three individual components: the website where the license plate information of stole cars is available, this android application which using the information from the website tries to match that information with captured video images, and a central server where, if a match has been found between the previous two stages, the match information is sent to. A diagram of this flow can be seen in Figure \ref{fig:top-level}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{plaatjes/top-down}
    \caption{Context diagram.}
    \label{fig:top-level}
\end{figure}%

Although all those three components are part of the whole system, this project only focuses on the application itself. A flowchart illustrating the general design and flow of the application is displayed in Figure \ref{fig:architecture}. Within an Android application all components run in the same thread by default, which is also known as the `main thread', and is identified in the flowchart as `UI' because it is used mainly to regulate all the processes related to the user interface. One of those processes, and also one of the most fundamental running in this thread, is the process which captures images from the device's camera. The process captures image frames at a set rate, the default being 1 second, in order to avoid the unnecessary capture of very similar images and, because image processing algorithms consist of a large number of calculations and therefore might take a long time to finish, to avoid overwhelming the application with too many frames. These images are then pushed into a buffer, called `Frames buffer', where they are kept until they are able to be processed. For the same reasons the camera only captures frames at a specific rate, this buffer has a limit of how many frames can be stored within with also the intention of only preserving images which are as recent as possible. Before a new frame is added the remaining frame must be processed. Further, the UI thread also manages the retrieval of the license plate information from the specified website. This process is repeated after a specified amount of time, the default being 30 minutes. This process runs until the application is terminated.

As explained before, image processing is rather heavy and it is necessary to use every tool available to increase the application's performance. One of these tools is multi-threading and apart from the UI thread this application uses two other kinds of threads, up to a total of four threads which is also the number of physical cores in the used device and therefore gives every thread a dedicated core. The processes called `Find bands' and `Find plate', which are the processes that find the vertical and horizontal location of the plate respectively and are discussed in the Implementation chapter, use a type of thread called a \emph{One-Call Thread}, which are threads used for a short period of time and only run when called. The other kind of thread is called a \emph{Permanent thread}. This type of thread is started during the initiation of the application, runs parallel to the UI thread and lives as long as the application itself. This process is responsible for checking whether the bands and plates buffers have available items and for calling the respective processes to process them. Further, if a plate is found then this thread applies text recognition to retrieve the displayed text and tries to match it with the database entries. If there is a match the application will save the plate information for a defined amount of time, the default being 30 minutes, to prevent that in case the application recognizes the same plate multiples times, it will not send the same or very similar information about the whereabouts of the vehicle and therefore spamming the central application. Furthermore, the plate's information will be bundled together with the current location of the smartphone, the current time and the confidence of the recognition. This bundled message will then be sent to a central server where it can then be distributed to the correct authorities. After this has been done or if there wasn't a match, the system starts again from the beginning.


\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{plaatjes/architecture-RoadEye-parallel}
    \caption{Application flow diagram.}
    \label{fig:architecture}
\end{figure}%

% #####################################################################################################################################################################################
\hoofdstuk{Implementation}
% #####################################################################################################################################################################################

The application consists of three main components: the algorithms for finding the vertical and horizontal locations of the license plates, and the text recognition component. Both localization algorithms are based on the work of Martinský Ondrej \cite{ondrej2007algorithmic}, with some slight modifications, which are explained in the following chapters, to fit the requirements of this application. 
The algorithms use the car in Figure \ref{fig:car-source} to demonstrate how they work.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.40\textwidth]{plaatjes/car}
    \caption{Source car image. \cite{source-car-fig}}
    \label{fig:car-source}
\end{figure}%

\paragraaf{Bands}

The first step to locating a license plate is to find its vertical location, which also known as a band. Using one of the most characteristic features of a Dutch license plate, which is its yellow colour and can be seen on Figure \ref{fig:dutch-plate}, it is possible to reduce the area of the image where the license plate might be located through the application of colour segmentation. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.3\textwidth]{plaatjes/dutch-plate}
    \caption{Example of a Dutch license plate. \cite{dutch-license-fig}}
    \label{fig:dutch-plate}
\end{figure}

Colour segmentation consists of fetching only the areas of an image which fall within a specified colour range and is usually used on an image which uses the HSV colour space representation. As seen in Figure \ref{fig:hsv}, HSV stands for Hue, Saturation, and Value and it is a way of representing colours on a computer. This in contrast to the most widely used colour space, the RGB colour space (Red, Green, Blue) which uses a combination of those very colours to represent a specific colour. The HSV colour space on the other hand uses the H-value to represent the pixel's colour and is defined in degrees (0$^{\circ}$ - 360$^{\circ}$), the S-value to represent how bleak or how colourful the pixel is and is defined with a percentage (0\% - 100\%), and the V-value to represent its brightness or darkness and is defined the same way as the saturation. This provides a system where it is simple to choose a colour range for the colour segmentation algorithm and is also the standard system for these kind of operations. The range chosen for the license plate lays between 40$^{\circ}$ and 50$^{\circ}$, which is broad enough to take into consideration the deviations in the colour of the plate caused by shadows and reflections.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.3\textwidth]{plaatjes/hsv}
    \caption{HSV colour space. \cite{hsv-fig}}
    \label{fig:hsv}
\end{figure}

As a result of segmenting the yellow colour from the source image, the image in Figure \ref{fig:color-segmented} is created, where the plate's location is quite visible. Often the segmented image also contains speckles from various small objects present in the image. These speckles are also visible in the previously mentioned image and might cause incorrect results when trying to locate the plate. To prevent this, a morphological closing operation \cite{morphclose} is performed. This operation works by dilating the image, which actually dilates its background and therefore removes small objects but also reduces the area of the plate, followed by eroding the dilated image, which does the inverse of the previous operation and returns the plate to its original size while the small objects are still gone. Further, because there are such things as yellow cars and other yellow objects, an extra step must be taken to decrease the chance of finding random objects. This is accomplished by making use of a characteristic of text and by extension of license plates, which is a high number of edges. By applying an edge detection algorithm, in this case the Sobel operator \cite{sobel} was used and its output is visible in Figure \ref{fig:edge-detected}, we still get a visible area where the plate is located but in case the source image contained large yellow areas, these areas are now mostly gone.

Once that is done, the application can start analysing the previous image for the license plate's possible location. This is done by summing up the intensity of every pixel on each row and therefore creating a graph where the density of edges on each row is displayed. Before making any decisions concerning the plate's location on the graph, a filter must be applied to the data to remove unwanted data and increase the desired area slightly, which is necessary for the next step of finding peaks. This filter is called a \emph{mean-filter} and works by summing up the values of a specific number of the previous and next data values, in the case of this application seven values are used, with the current value and diving it by the total number of values. In Figure \ref{fig:mean-filter} an example is displayed which illustrates the effect of a mean-filter. The results in the `smooth' graph of the sum of the intensity of every pixel on each row, displayed in Figure \ref{fig:possible-bands}. The next step and last step is finding the potential plate areas and this is done by searching for a number of the highest peaks in the graph, with three being the default. The algorithm tries to find multiple possible locations in case an object in the image happens to have a higher edge density than the plate, and therefore increasing the chance of still finding it. The way the application finds peaks is by finding the highest value in the data set and then searching for the right and left boundary of the peak by iterating towards its respective side until it finds a value which is equal to or smaller than 10\% of the peak's value. The previous mean-filter is used to prevent the graph from suddenly dropping bellow this 10\% in case there happen to be no pixels in that specific row. The coordinates of both boundaries are then saved and the area in between both coordinates is made equal to zero, or \emph{zeroised}. By rinsing and repeating this process for the chosen number of times, the bands displayed on Figure \ref{fig:possible-bands} are found. The flow of this process is illustrated in Figure \ref{fig:find-band-flow}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{plaatjes/mean-filter}
    \caption{Example of mean-filter.}
    \label{fig:mean-filter}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{plaatjes/find-band-flow}
    \caption{Flow of band location.}
    \label{fig:find-band-flow}
\end{figure}

\begin{figure}[ht]
        \centering
        \begin{subfigure}{0.7\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/yellow-segment}
            \caption{Colour segmentation.}
            \label{fig:color-segmented}
        \end{subfigure}%
        
        \begin{subfigure}{0.7\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/edge-detection}
            \caption{Edge detection.}
            \label{fig:edge-detected}
        \end{subfigure}%

        \begin{subfigure}{0.7\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/3-peaks}
            \caption{Possible band(s).}
            \label{fig:possible-bands}
        \end{subfigure}%

        \caption{Phases from band localization.}
        \label{fig:find-band}
\end{figure}

\clearpage

\paragraaf{Plates}

After finding the bands, these can be further processed to find the exact location of the plate. Using the binary version of the band's image, a graph can be generated just like before, but instead of summing up all values on each row, the values of each column are now summed. Once the graph has been created, the mean-filter is also applied for the same reason as before. Using the filtered data the plate is then located by searching for the largest cluster of peaks, as shown in Figure \ref{fig:band-cropped}, which are equivalent to the letters on the plate. The algorithm works by iterating the graph until a data cluster is found, from which the algorithm then saves the start coordinate and keeps iterating the remainder of the graph until it reaches the end of the current cluster. The size of the cluster is then saved and after repeating this process for every data cluster present in the graph, the largest one is chosen as the plate's location. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{plaatjes/plate-graph}
    \caption{Horizontal localisation of the plate.}
    \label{fig:band-cropped}
\end{figure}

This gives an image of the plate with a rather larger border of undesired parts of the image, as shown in Figure \ref{fig:skewed-plate}. The reason for this is that depending on the angle at which the image was captured at, the plate might be skewed and the text won't therefore be at a 90$^{\circ}$ angle. This makes it difficult for the OCR software to recognise the text properly. To correct the skewness the bounding box of the plate must be calculated, which is a quadrangle that surrounds the plate's area and from where its four vertices can be retrieved. The box can be seen in Figure \ref{fig:skewed-bounding-box}. Using these points, the angle at which the plate is skewed can then be calculated and the image can then be de-skewed using the warp perspective algorithm \cite{warpperspective} as displayed in Figure \ref{fig:rotated-plate}. 

Finally, only a few last steps are necessary to complete the localisation and processing of the plate before the OCR software takes over. But before, a simple filter is applied to the plate candidate to filter out wrongly detected plates. This is done by calculating the ration between the width and the height of the plate. A rectangular Dutch car license plate has a size of 52cmx11cm \cite{plate-size}. This means the width to height ratio is around 4.7. By using a range between 4 and 5 to compensate for some deviations caused by the angle the image was captured at, most incorrect plate candidates are filtered out. If the plate's ratio is within the right range, the plate can be further processed. Using the de-skewed plate, a binary image must then be created to allow for the removal of unwanted artefacts still present on the image, e.g. borders. The binary image is created by applying a threshold algorithm onto a greyscale version of the plate, which converts every pixel with an intensity value above a certain threshold to a black pixel and everything else to white. The used threshold algorithm is an adaptive threshold algorithm, which gets its name because of its ability to adapt the threshold value of a pixel according to the neighbouring pixels. In this case the algorithm calculates the mean value of the sum of the pixels around the threshold pixel. This gives a better result than using a fixed value, because the lighting condition is not the same on every image, or a threshold algorithm like Otsu's method \cite{otsu} which requires a distinct difference between foreground and background, which is not always available in the case of a license plate. After applying the threshold algorithm, a binary image is created containing the background in white while the text and eventually some artefacts are in black. The last step left to take is to discriminate the text from everything else and therefore creating an image fit for text recognition. This is accomplished by applying a contour finding algorithm \cite{suzuki}, which finds the outline of every item in the image. By using only the contours which are enclosed within another contour and in turn do not contain other contours within themselves, as is the case of the letters' contours as they are located within the contour of the license plate and contain no further contours inside them. This is possible because the contours algorithm creates a hierarchy list of every contour and whether that contour has a parent and/or child. One last filter is applied to the characters to filter out unwanted artefacts or images which are not plates. This is done by sorting the contours by size and only displaying the largest six contours present. Six was chosen because Dutch license plates only consist of 6 alpha-numeric characters. If there are more than six contours, the unwanted contours are then filtered out, and if there are less then 6 contours, there's a large chance that it's not a license plate. This results in Figure \ref{fig:6-characters}. 

\begin{figure}[ht]
        \centering
        \begin{subfigure}{0.33\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/skewed-plate}
            \caption{Skewed plate.}
            \label{fig:skewed-plate}
        \end{subfigure}%
        ~ 
        \begin{subfigure}{0.33\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/skewed-plate-box}
            \caption{Bounding box of the plate.}
            \label{fig:skewed-bounding-box}
        \end{subfigure}%
        ~ 
        \begin{subfigure}{0.33\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/rotated-plate}
            \caption{De-skewed plate.}
            \label{fig:rotated-plate}
        \end{subfigure}%

        \begin{subfigure}{0.33\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/remove-border-plate}
            \caption{Threshold of plate.}
            \label{fig:threshold-plate}
        \end{subfigure}%
        ~
        \begin{subfigure}{0.33\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/6-characters}
            \caption{Plate characters.}
            \label{fig:6-characters}
        \end{subfigure}%
        \caption{Phases from the plate de-skewing process.}
        \label{fig:deskewing-plate}
\end{figure}

After this whole process, the plate is now ready to have the OCR software applied to it. The flow of this process is illustrated in Figure \ref{fig:find-plate-flow}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{plaatjes/find-plate-flow}
    \caption{Flow of plate location.}
    \label{fig:find-plate-flow}
\end{figure}%

\clearpage

\paragraaf{Text recognition}

Although the Tesseract library works really well most of the time, it requires some training in some specific cases. The text displayed on license plates is one of those cases because it uses an unique font designed specifically to be used on plates. There is no official version of this font publicly available, but using LeFly's \cite{lefly} interpretation it was possible to train Tesseract to recognise this type of text. The font used for the training can be seen in Figure \ref{fig:plate-font}. Not every character has been added to the training text simply because not every character is used in license plates. The reasons for this ranges from characters being reserved for special plates, e.g. the royal family or diplomats, to characters that are too alike, e.g. the `I' and the `1' or `O' and the `0'.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{plaatjes/font}
    \caption{License plate font.}
    \label{fig:plate-font}
\end{figure}%

Using the image displayed above and the external tools provided by the Tesseract library, training data can be generated. Tesseract does this by segmenting every item on the image and creating a file with its best guess at which character is represented on the image, its location on the image, and its size. This data is displayed in Figure \ref{fig:text-data}. After this file has been checked for possible mistakes, it can then be used to generated further necessary files where information on the shape of the characters, etc. are stored. Finally all the data is then bundled into a single file which can later be used with the recognition software.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.3\textwidth]{plaatjes/text-data}
    \caption{Font data.}
    \label{fig:text-data}
\end{figure}%

Now if Tesseract is applied to the plate in Figure \ref{fig:unslanted-plate} using this training data, the results will be much better than without it.

\paragraaf{Database matching}

Once the plate has been found and the text has been parsed, the only thing left to do is to see if it's one of the cars the application is looking for. This component consists of two separate parts: matching the parse text with the database and updating the database.

First the application must retrieve a list with information about license plates of cars which are being searched for. Without this step it won't be possible to match the parsed text. This list is retrieved from a specific website using an HTTP socket. The website used for this application was a local dummy website. The information was stored in the JavaScript Object Notation (JSON) format. This is a simple way of storing and sending information objects between servers and clients. Once the information was retrieved from the website, it is stored in a file on the smartphone's storage. This process runs on a timer, which repeats itself after a specified amount of time, 30 minutes being the default.

The second part of this component is very simple. Once the text has been parsed, the application runs the parsed information through the database looking for a match. If a match is indeed found, the application will then retrieve the current GPS location and bundle it together with the plate information and the current time in a new JSON object and will the send it again via a HTTP socket. An example of a JSON annotation is displayed in Figure \ref{fig:json}.

\begin{figure}
    \begin{lstlisting}[language=json]
    { 
        "Plate": "XX-123-Y",
        "Date": "01-01-1970 00:00",
        "Latitude": "76.92061352",
        "Longitude": "41.04492187" 
    }
    \end{lstlisting}
    \caption{JSON annotation example}
    \label{fig:json}
\end{figure}

% #####################################################################################################################################################################################
\hoofdstuk{Validation}
% #####################################################################################################################################################################################

To define where the strengths and weaknesses of the software lie, some validation tests must be performed. These tests will provide information which in turn will be used to answer the research questions stated at the beginning of this thesis and, by extension, draw a conclusion on whether the project was successful. These tests are focused on three elements: the maximum distance and angle at which the application is able to present reliable results and how well it performs while inside a driving car. These tests were performed using a resolution of 1360x720 pixels, the highest possible for video on the chosen smartphone.

\paragraaf{Distance}

During this validation phase the distance limitations of the application are tested. According to the FAQ of the Tesseract library \cite{tesseract-faq}, a minimum text size for reasonable accuracy is advised. It states that to get reasonable results each character must have at least a height of about 20 pixels, that below an height of 10 pixels there's a very little chance of accurate results, and below 8 pixels the characters will possibly be ignored as just image noise. These heights might differ with the use of different fonts. At a resolution of $1360x720$ pixels a plate of $52x11$ cm has the following dimensions in pixels at different distances:

\begin{itemize}
	\item 3 meters: $118x24$ pixels
	\item 4 meters: $87x17$ pixels
	\item 5 meters: $72x14$ pixels
	\item 6 meters: $58x12$ pixels
\end{itemize}

This means that at a distance of 3 meters, the application should be able to read the text effortlessly. But the further away the vehicle gets to the height boundary of 10 pixels, the fewer correct results can be retrieved. At the distances of 4 and 5 meters, it should still be able to read the text but at a distance of 6 meters, the height of the characters might be to small to read correctly.

The results are displayed in Figure \ref{fig:distance-test}. On Figure \ref{fig:3m-0a}, the text recognised is rather sharp and the OCR software has absolutely no problem parsing it. But the further away we go, the less and less sharp the text gets. Figures \ref{fig:4m-0a} and \ref{fig:5m-0a} still look clear and are parsed well, but once we get to the around 6 meters of Figure \ref{fig:6m-0a} the parsed text starts getting some inconsistencies. Although it might still be possible the application will parse the text correctly, more often than not it will return incorrect results. The maximum reliable distance lies therefore between 5 and 6 meters. This conforms largely with the heights provided by the Tesseract's FAQ, although the text doesn't have to get to a height of 10 pixels or fewer before not being able to get reasonable results. The font used in plates might be to blame for these discrepancies.

% \clearpage

\begin{figure}[ht]
        \centering
        \begin{subfigure}{0.5\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/test-3m-0a}
            \caption{Vehicle at 3 meters, 0$^{\circ}$.}
            \label{fig:3m-0a}
        \end{subfigure}%
        ~ 
        \begin{subfigure}{0.5\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/test-4m-0a}
            \caption{Vehicle at 4 meters, 0$^{\circ}$.}
            \label{fig:4m-0a}
        \end{subfigure}%
        % ~ 

        \begin{subfigure}{0.5\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/test-5m-0a}
            \caption{Vehicle at 5 meters, 0$^{\circ}$.}
            \label{fig:5m-0a}
        \end{subfigure}%
        ~
        \begin{subfigure}{0.5\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/test-6m-0a}
            \caption{Vehicle at 6 meters, 0$^{\circ}$.}
            \label{fig:6m-0a}
        \end{subfigure}%

        \caption{Results at varied distances.}
        \label{fig:distance-test}
\end{figure} %

\paragraaf{Angle}

To find what the maximum angle is at which the application still works reliably, various angles were tested in an incremental way. Starting at the 6 meter 0$^{\circ}$ mark, because 6 meters was the last position the application worked at this angle, a small step was continuously taken in a circle around the vehicle and the application was tested. If no angle worked at this distance, the same was then repeated at a closer distance. By repeating this process, the boundary of the reliable working area was found. As shown in Figure \ref{fig:4m-47.5a}, the application was able to parse the text correctly, but in Figure \ref{fig:4m-47.5a-more} which is only a step further to the right, the application didn't work correctly. This point was located at a distance of 4 meters from the car and at an angle around 47$^{\circ}$.

\clearpage

\begin{figure}[H]
        \centering
        \begin{subfigure}{0.50\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/test-4m-47,5a}
            \caption{Vehicle at 4 meters, 47$^{\circ}$.}
            \label{fig:4m-47.5a}
        \end{subfigure}%
        ~ 
        \begin{subfigure}{0.50\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/test-4m-47,5a+}
            \caption{Vehicle at 4 meters, \textgreater 47$^{\circ}$.}
            \label{fig:4m-47.5a-more}
        \end{subfigure}%
        % ~ 

        \caption{Results at varied angles.}
        \label{fig:angle-test}
\end{figure}%

% \clearpage

\paragraaf{Reliable area}

Using the information gathered using the past two tests, an area can be derived within which the application works well and reliably. This area is depicted in Figure \ref{fig:road-situation} and the scenario was created using the road design criteria from the province of Zuid-Holland \cite{road-design}. Looking at this figure it's clear that the application can process the plates of vehicles both in the same lane, at a distance of 5 meters, and in the adjacent lanes, at a distance of 4 meters, while driving at a safe distance on an inside road or during a slow commute on the highway.


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{plaatjes/roadeye-road}
    \caption{Reliable detection area.}
    \label{fig:road-situation}
\end{figure}%

\clearpage

\paragraaf{Real scenario}

Once the distance and angle limitations of the application have been found, they must be tested on a real scenario to see how well the application handles real usage. This was tested while inside a car driving normally on an inside road. One of the situations encountered is displayed in Figure \ref{fig:real-scenario-1}. The vehicle in front of the camera is within the distance limit of 5 meters and the application is able to find the plate perfectly. But even though the plate is within the reliable detection area, the text is incorrectly parsed. The application mistakes the letter `S' for the number `5' or even the number `3'. This exposes a limitation that might impact the accuracy of the application. 

One other situation the application isn't able to handle correctly is displayed in Figure \ref{fig:real-scenario-2}. Even though the car in the lane left of the application is within the reliable detection area, the application is not able to find the location of the plate, let alone parse its text which in this case is not even visible. This because the plate on the image appears as only an yellow blur without any visible text. This is a result of the combined speeds of both the car where the application is located and the incoming car making it impossible for the smartphone's camera to capture a useful image.

The last situation, depicted in Figure \ref{fig:real-scenario-3}, proves that if a car is indeed at a distance larger the calculated reliable distance, that the application is not able to find its location.

\begin{figure}[ht]
        \centering
        \begin{subfigure}{0.50\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/real-scenario-1}
            \caption{Incorrectly parsed text.}
            \label{fig:real-scenario-1}
        \end{subfigure}%
        ~ 
        \begin{subfigure}{0.50\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/real-scenario-2}
            \caption{Incoming car.}
            \label{fig:real-scenario-2}
        \end{subfigure}%
        % ~ 

        \begin{subfigure}{0.50\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/real-scenario-3}
            \caption{Car at a great distance.}
            \label{fig:real-scenario-3}
        \end{subfigure}%

        \caption{Results at varied angles.}
        \label{fig:real-scenario}
\end{figure}%

\clearpage

\paragraaf{Adjacent vehicles}

One other possible problem of this application is attributed to the way its plate location software works. By only retrieving the largest `plate' on each band, it is possible that the application will miss a plate if the vertical locations of two car plates happen to overlap. To test this problem an image was created, displayed in Figure \ref{fig:same-height-source}, with two different cars next to each other with their license plates at around the same height. Further, another image was created, displayed in Figure \ref{fig:different-height-source}, with the same cars but then at different heights to test if both plates are located if the vertical locations of both plates do not overlap.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{plaatjes/85}
    \caption{Reliable detection area.}
    \label{fig:same-height-source}
\end{figure}%

Starting with the image with the overlapping plates, this image was processed using the application and the result is displayed in Figure \ref{fig:same-height-band}. Because the algorithm only looks for the largest group of peaks in each band, it also only finds one of the bands present in this band. In this case the right plate happens to be larger than its left counterpart and is therefore indeed the only one chosen. This reduces the amount of plates retrieved from camera images in these kind of scenarios.


\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{plaatjes/85-graph}
    \caption{Reliable detection area.}
    \label{fig:same-height-band}
\end{figure}%

To test whether the application is able to find multiples plates within an image if those plates' vertical locations do not overlap, the second image was processed using the application.

\clearpage 

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{plaatjes/85-offset}
    \caption{Reliable detection area.}
    \label{fig:different-height-source}
\end{figure}%

Because the plates' vertical locations do not overlap, they end up in different bands. Both these bands are displayed in Figure \ref{fig:different-height-bands}. As it's possible to see in both displayed images, the application is undoubtedly able to locate both plates. This reduces the possible scenarios where the application will only find one of the multiple plates present to the scenarios where the plates are located in overlapping vertical locations.  

\begin{figure}[ht]
        \centering
        \begin{subfigure}{\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/85-offset-1}
            \caption{Incorrectly parsed text.}
            \label{fig:different-height-band-1}
        \end{subfigure}%

        \begin{subfigure}{\textwidth}
            \includegraphics[width=\textwidth]{plaatjes/85-offset-2}
            \caption{Incoming car.}
            \label{fig:different-height-band-2}
        \end{subfigure}%

        \caption{Results at varied angles.}
        \label{fig:different-height-bands}
\end{figure}%

% #####################################################################################################################################################################################
\hoofdstuk{Market research}
% #####################################################################################################################################################################################

This research was done with the goal of finding similar products, both consumer and government, which are used for the same of similar purposes and discovering, if possible, how they tackled their problems and what they can and cannot do. This information can then be used for finding in which direction the literature research should go and to find a scenario where this project can solve a problem for which there is no available product. 

\paragraaf{Government}

The government has employed multiple types of camera's to find transgressing drivers all over the country. The most widely used ones are the \emph{speed cameras} and the \emph{ANPR (Automatic Number Plate Recognition) cameras}. Speed cameras are cameras which are posted along roads and only activate whenever a vehicle drives by while exceeding the speed limit. These cameras then take a picture of the rear-end of the vehicle, the reason for this is to not scare the driver with the camera's flash. ANPR cameras on the other hand are cameras which are constantly on, while scanning the roads for license plates.  There are for certain 1625 ANPR cameras \cite{anpr-cameras} currently in use, although they are not all ready to be used in investigations. If these cameras are ever linked together with other kinds of cameras, e.g. speed cameras and intersection cameras, this would create a network of around 5000 cameras \cite{speed-cameras}. A map illustration of where these cameras are located is displayed in Figure \ref{fig:cameras-netherlands}. Although the amount of cameras and their locations are publicly known, there is no information about their inner workings apart from their general purpose, which comes down to recognizing license plates. There is also no information regarding whether they are being used for investigations. This is probably to prevent people from easily discovering ways to avoid detection by these cameras.

From the above mentioned map, there are still some observations to be made. The largest part of the cameras are located along main roads and at the largest cities, i.e. highways or Rotterdam and Amsterdam, to be able to scan the most cars possible. This leaves a whole in most most rural areas and cities in the north/north-east with barely any surveillance.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{plaatjes/anpr-cameras}
    \caption{Location of cameras in The Netherlands.}
    \label{fig:cameras-netherlands}
\end{figure}%

\paragraaf{Consumer}

There are multiple companies which create consumer versions of ANPR cameras. These cameras come with all kinds of technical specifications and sizes and were created to be used in different scenarios. A list of some of these cameras is displayed in Appendix \ref{sec:3}. This list shows whether or how well these cameras conform to a couple of requirements, i.e. the working distance and angle, a car's maximum speed to be recognized successfully and whether their mobile or static. The data of this application is also on the list for comparison purposes. Although there is a lot of information which wasn't available about these products, it's still possible to do some comparisons. Firstly, most of the available cameras perform a lot better than this application. This reason for this is that they have dedicated and more expensive hardware when compared to any smartphone currently available on the market. From the few cameras which provided the view angle at which they work, one of the things that pop out is their limited angle. This makes it possible to get better images at larger distances even if the cameras have a lower resolution than the smartphone. Another thing that stands out is that most of these cameras are static. This means that they have to be hanged and 

\paragraaf{Conclusion}

